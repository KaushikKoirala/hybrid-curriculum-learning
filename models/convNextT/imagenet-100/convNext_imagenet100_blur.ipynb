{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNeXt-Tiny Blur Training on ImageNet-100\n",
    "This notebook implements a baseline ConvNeXt-Tiny model trained on ImageNet-100, focusing on modernizing the architecture to align with ViT principles while retaining the convolutional nature.\n",
    "\n",
    "## Dataset: ImageNet-100\n",
    "- 100 classes subset of ImageNet\n",
    "\n",
    "- 224x224 input images\n",
    "\n",
    "- Standard data augmentation\n",
    "\n",
    "## Model: ConvNeXt-Tiny\n",
    "- Architecture based on modernizing a ResNet structure towards Vision Transformer design\n",
    "\n",
    "- ~28.6M parameters (specific to ConvNeXt-Tiny)\n",
    "\n",
    "- Features include: large kernel sizes, use of Layer Normalization, and GELU activation\n",
    "\n",
    "- Conventional training (standard image classification setup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchsummary torchvision tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, os, time, copy, random\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from contextlib import nullcontext\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED);  torch.manual_seed(SEED);  torch.cuda.manual_seed_all(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = dict(\n",
    "    num_epochs       = 100,          # keep it or change as you wish\n",
    "    batch_size       = 128,          # tune to your GPU memory\n",
    "    lr               = 4e-3,         # a good starting point for ImageNet-size data\n",
    "    weight_decay     = 0.05,\n",
    "    warmup_epochs    = 5,\n",
    "    num_workers      = 8,            # ImageNet is stored on disk → use more workers\n",
    "    image_size       = 224,\n",
    "    blur_percent     = 0.2,\n",
    "    amp              = True,\n",
    "    pretrained       = False,\n",
    "    ckpt_dir         = \"./imagenet_blur_checkpoint\",\n",
    "\n",
    "    dataset_path     = \"ImageNet100_224\",\n",
    "    num_classes      = 100\n",
    ")\n",
    "Path(CFG[\"ckpt_dir\"]).mkdir(exist_ok=True)\n",
    "\n",
    "CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imagenet100_loaders(data_path, batch_size=128, num_workers=5):\n",
    "    \"\"\"Load ImageNet-100 dataset with standard augmentation\"\"\"\n",
    "    \n",
    "    # ImageNet normalization\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                   std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    # Training transforms with augmentation\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    \n",
    "    # Validation transforms (no augmentation)\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    \n",
    "    blur_transform_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),  # adjust strength as desired\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    \n",
    "    # Load datasets\n",
    "    train_dir = Path(data_path) / 'train'\n",
    "    val_dir = Path(data_path) / 'val'\n",
    "    \n",
    "    train_dataset_normal = datasets.ImageFolder(train_dir, transform=transform_train)\n",
    "    train_dataset_blur = datasets.ImageFolder(train_dir, transform=blur_transform_train)\n",
    "    val_dataset = datasets.ImageFolder(val_dir, transform=transform_val)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader_normal = DataLoader(\n",
    "        train_dataset_normal, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=num_workers, \n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    train_loader_blur = DataLoader(\n",
    "        train_dataset_blur, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=num_workers, \n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        num_workers=num_workers, \n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader_normal, train_loader_blur, val_loader, train_dataset_normal, train_dataset_blur, val_dataset\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading ImageNet-100 dataset...\")\n",
    "train_loader_normal, train_loader_blur, val_loader, train_dataset_normal, train_dataset_blur, val_dataset = get_imagenet100_loaders(\n",
    "    data_path=CFG['dataset_path'],\n",
    "    batch_size=CFG['batch_size'],\n",
    "    num_workers=CFG['num_workers']\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset_normal)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Number of classes: {len(train_dataset_normal.classes)}\")\n",
    "print(f\"Classes: {train_dataset_normal.classes[:10]}...\" if len(train_dataset_normal.classes) > 10 else f\"Classes: {train_dataset_normal.classes}\")\n",
    "print(f\"Training batches: {len(train_loader_normal)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG[\"pretrained\"]:\n",
    "    weights = models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1\n",
    "else:\n",
    "    weights = None\n",
    "\n",
    "model = models.convnext_tiny(weights=weights)\n",
    "\n",
    "# Replace the classifier to output 100 classes instead of 10\n",
    "in_features = model.classifier[-1].in_features\n",
    "model.classifier[-1] = nn.Linear(in_features, CFG[\"num_classes\"])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.optim.lr_scheduler import LinearLR, CosineAnnealingLR, SequentialLR\n",
    "\n",
    "criterion  = nn.CrossEntropyLoss()\n",
    "optimizer  = torch.optim.AdamW(model.parameters(),\n",
    "                               lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
    "\n",
    "\n",
    "def build_warmup_cosine_scheduler(optimizer, steps_per_epoch, num_epochs,\n",
    "                                  warmup_epochs=1, eta_min=1e-5, accum_steps=1):\n",
    "    steps_per_epoch = math.ceil(steps_per_epoch / max(1, accum_steps))\n",
    "    total_steps = num_epochs * steps_per_epoch\n",
    "    warmup_steps = warmup_epochs * steps_per_epoch\n",
    "    cosine_steps = max(1, total_steps - warmup_steps)\n",
    "\n",
    "    scheds = []\n",
    "    milestones = []\n",
    "\n",
    "    if warmup_steps > 0:\n",
    "        # start_factor cannot be 0 in some versions; use a tiny epsilon if needed.\n",
    "        s1 = LinearLR(optimizer, start_factor=1e-8, end_factor=1.0, total_iters=warmup_steps)\n",
    "        scheds.append(s1)\n",
    "        milestones.append(warmup_steps)\n",
    "\n",
    "    s2 = CosineAnnealingLR(optimizer, T_max=cosine_steps, eta_min=eta_min)\n",
    "    scheds.append(s2)\n",
    "\n",
    "    scheduler = SequentialLR(optimizer, schedulers=scheds, milestones=milestones or [0])\n",
    "    return scheduler\n",
    "\n",
    "scheduler = build_warmup_cosine_scheduler(\n",
    "    optimizer,\n",
    "    steps_per_epoch=len(train_loader_normal),\n",
    "    num_epochs=CFG[\"num_epochs\"],\n",
    "    warmup_epochs=CFG[\"warmup_epochs\"]\n",
    ")\n",
    "scaler     = torch.cuda.amp.GradScaler(enabled=CFG[\"amp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, targets, topk=(1,)):\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        _, pred = preds.topk(maxk, dim=1, largest=True, sorted=True)\n",
    "        pred   = pred.t()\n",
    "        correct= pred.eq(targets.view(1, -1).expand_as(pred))\n",
    "        return [correct[:k].reshape(-1).float().mean().item()*100. for k in topk]\n",
    "\n",
    "\n",
    "def run_epoch(loader, model, optimizer=None, epoch:int=0, phase:str=\"train\"):\n",
    "    \"\"\"\n",
    "    If `optimizer` is given → training mode, otherwise evaluation mode.\n",
    "    Memory-safe: no graph is kept when we don't need gradients.\n",
    "    \"\"\"\n",
    "    train = optimizer is not None\n",
    "    model.train(train)\n",
    "\n",
    "    running_loss, running_acc = 0.0, 0.0\n",
    "    steps = len(loader)\n",
    "\n",
    "    bar = tqdm(loader, desc=f\"{phase.title():>5} | Epoch {epoch:02}\", leave=False)\n",
    "\n",
    "    # Choose the right context managers\n",
    "    grad_ctx = nullcontext() if train else torch.no_grad()\n",
    "    amp_ctx  = torch.amp.autocast(device_type=\"cuda\",\n",
    "                                  dtype=torch.float16,\n",
    "                                  enabled=CFG[\"amp\"] and torch.cuda.is_available())\n",
    "\n",
    "    with grad_ctx:\n",
    "        for images, labels in bar:\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device)\n",
    "\n",
    "            with amp_ctx:\n",
    "                outputs = model(images)\n",
    "                loss    = criterion(outputs, labels)\n",
    "\n",
    "            if train:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer); scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_acc  += accuracy(outputs, labels)[0]\n",
    "            bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    torch.cuda.empty_cache()     # free any leftover cached blocks\n",
    "    return running_loss/steps, running_acc/steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect() # These commands help you when you face CUDA OOM error\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "checkpoint_dir = CFG['ckpt_dir']\n",
    "\n",
    "print(checkpoint_dir)\n",
    "print(os.path.exists(checkpoint_dir))\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, scheduler, metrics, epoch, path):\n",
    "    torch.save(\n",
    "        {'model_state_dict'         : model.state_dict(),\n",
    "         'optimizer_state_dict'     : optimizer.state_dict(),\n",
    "         'scheduler_state_dict'     : scheduler.state_dict() if scheduler is not None else '',\n",
    "         'metric'                   : metrics,\n",
    "         'epoch'                    : epoch},\n",
    "         path)\n",
    "\n",
    "\n",
    "def load_model(model, optimizer=None, scheduler=None, path=f\"{CFG['ckpt_dir']}/current_epoch.pth\"):\n",
    "    checkpoint = torch.load(path, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    else:\n",
    "        optimizer = None\n",
    "    if scheduler is not None:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    else:\n",
    "        scheduler = None\n",
    "    epoch = checkpoint['epoch']\n",
    "    metrics = checkpoint['metric']\n",
    "    return model, optimizer, scheduler, epoch, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_acc = 0.0\n",
    "patience = 16\n",
    "epoches_no_improve = 0\n",
    "\n",
    "history = {\"train_loss\": [], \"train_acc\": [],\n",
    "           \"val_loss\": [],   \"val_acc\": []}\n",
    "\n",
    "blur_epochs = int(CFG[\"num_epochs\"] * CFG[\"blur_percent\"])\n",
    "\n",
    "for epoch in range(1, CFG[\"num_epochs\"]+1):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # pick which train loader to use this epoch\n",
    "    use_blur = epoch <= blur_epochs\n",
    "    loader_this_epoch = train_loader_blur if use_blur else train_loader_normal\n",
    "    phase_name = f\"train-{'blur' if use_blur else 'normal'}\"\n",
    "\n",
    "    tr_loss, tr_acc = run_epoch(loader_this_epoch, model, optimizer, epoch, phase_name)\n",
    "    val_loss, val_acc= run_epoch(val_loader,   model, None,     epoch, \"val\")\n",
    "\n",
    "    history[\"train_loss\"].append(tr_loss); history[\"train_acc\"].append(tr_acc)\n",
    "    history[\"val_loss\"].append(val_loss);   history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    if val_acc >= best_val_acc:\n",
    "        epoches_no_improve = 0\n",
    "        best_val_acc = val_acc\n",
    "        \n",
    "        metrics = {\n",
    "            \"train_loss\": tr_loss,\n",
    "            \"train_acc\": tr_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_loss,\n",
    "        }\n",
    "        save_model(model, optimizer, scheduler, metrics, epoch, f\"{CFG['ckpt_dir']}/best_convnext_tiny.pth\")\n",
    "        print(\"Saved best val acc model\")\n",
    "    \n",
    "    else:\n",
    "        epoches_no_improve += 1\n",
    "        \n",
    "    try:\n",
    "        os.replace(f\"{CFG['ckpt_dir']}/current_epoch.pth\", f\"{CFG['ckpt_dir']}/last_epoch.pth\")\n",
    "        print(\"Saved last epoch model\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred when creating last.pth: {e}\")\n",
    "        \n",
    "    save_model(model, optimizer, scheduler, metrics, epoch, f\"{CFG['ckpt_dir']}/current_epoch.pth\")\n",
    "    print(f\"Saved epoch {epoch} model\")\n",
    "\n",
    "    print(f\"Epoch {epoch:02}/{CFG['num_epochs']} \"\n",
    "          f\"| train loss {tr_loss:.4f} acc {tr_acc:.2f}% \"\n",
    "          f\"| val loss {val_loss:.4f} acc {val_acc:.2f}% \"\n",
    "          f\"| lr {scheduler.get_last_lr()[0]:.2e} \"\n",
    "          f\"| time {(time.time()-t0):.1f}s\")\n",
    "\n",
    "    if epoches_no_improve >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, scheduler, start_epoch, metrics = load_model(model, optimizer, scheduler, f\"{CFG['ckpt_dir']}/best_convnext_tiny.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer, scheduler, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
